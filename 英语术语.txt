æœºå™¨å­¦ä¹ æ¨¡å‹ï¼šç”¨ä¸€äº›å¤æ‚çš„å‡½æ•°æ¥é™å®šæ¨¡å‹ï¼Œçº¿æ€§å¯åˆ†æ˜¯ç”¨è¶…å¹³é¢çš„æ¨¡å‹ï¼Œå†ä»æ¨¡å‹é‡Œé¢ç•™å‡ºä¸€äº›å¾…å®šçš„å‚æ•°ï¼Œå†ç”¨è®­ç»ƒçš„æ ·æœ¬ä»£å…¥ç®—æ³•æ¥ç¡®å®šwå’Œbçš„å–å€¼
æœºå™¨å­¦ä¹ ä¸­å¯¹é«˜ç»´åº¦çš„å¤„ç†è¿œè¿œè¶…è¿‡äºäºº

ç»´æ•°çš„ä¸åŒï¼Œå†³å®šç”¨å¯¼æ•°è¿˜æ˜¯åå¯¼æ•°
ä¸€ç»´çš„ç”¨dï¼ˆ**ï¼‰å¯¼æ•°
å¤šç»´çš„ç”¨é˜¿å°”æ³•aï¼ˆ**ï¼‰ åå¯¼æ•°
invæ˜¯ä»€ä¹ˆå‡½æ•°	çŸ©é˜µæ±‚é€†å‡½æ•°
---
ä»£ä»·å‡½æ•°ä¹Ÿå«åšå¹³æ–¹è¯¯å·®å‡½æ•°------ç›®æ ‡æ˜¯æ‰¾å‡ºå‚æ•°theta-----èƒ½ä½¿ä»£ä»·å‡½æ•°ğ½æœ€å°åŒ–çš„å‚æ•°ğœƒ0å’Œğœƒ1çš„å€¼ã€‚

ç›‘ç£å­¦ä¹ ã€‚å…¶åŸºæœ¬æ€æƒ³æ˜¯ï¼šæˆ‘ä»¬æ•°æ®é›†ä¸­çš„æ¯ä¸ªæ ·æœ¬éƒ½æœ‰ç›¸åº”çš„â€œæ­£ç¡®ç­”æ¡ˆâ€ã€‚å†æ ¹æ®è¿™äº›æ ·æœ¬ä½œå‡ºé¢„æµ‹

åŸé—®é¢˜æœ€å°åŒ–ï¼Œåˆ™å¯¹åº”çš„å¯¹å¶é—®é¢˜æœ€å¤§åŒ–

hyperplane  	è¶…å¹³é¢
slack variable  	æ¾å¼›å˜é‡
supervised learning		ç›‘ç£å­¦ä¹ 
unsupervised learning	æ— ç›‘ç£å­¦ä¹ 
tumor size   è‚¿ç˜¤å¤§å°
uniformity    å‡åŒ€åº¦
clump thickne	å›¢å—åšåº¦
Linear Regression with One Variable	å•å˜é‡çº¿æ€§å›å½’
Training Set	è®­ç»ƒé›†
hypothesis 	å‡è®¾
parameter	å‚æ•°
modeling error	å»ºæ¨¡è¯¯å·®
local mininum	å±€éƒ¨æœ€å°å€¼
global minimum	å…¨å±€æœ€å°å€¼ s
batch gradient descent	æ‰¹é‡æ¢¯åº¦ä¸‹é™
repeat until convergence	é‡å¤ç›´åˆ°æ”¶æ•›
learning rate	ğ‘æ˜¯å­¦ä¹ ç‡ 	
Linear Regression with Multiple Variables	å¤šå˜é‡çº¿æ€§å›å½’
polynomial regression		å¤šé¡¹å¼å›å½’
dependent variable		åº”å˜é‡
decision boundary		å†³ç­–è¾¹ç•Œ
regularization term		æ­£åˆ™é¡¹
forward propagation	å‰å‘ä¼ æ’­ç®—æ³•ï¼šæ­£å‘ä¼ æ’­æ–¹æ³•ï¼Œæˆ‘ä»¬ä»ç¬¬ä¸€å±‚
				å¼€å§‹æ­£å‘ä¸€å±‚ä¸€å±‚è¿›è¡Œè®¡ç®—ï¼Œç›´åˆ°æœ€åä¸€å±‚çš„â„ğœƒ(ğ‘¥)ã€‚
Backpropagation Algorithm	 åå‘ä¼ æ’­ç®—æ³•
cross validation error 	äº¤å‰éªŒè¯è¯¯å·®
degree of polynomial	å¤šé¡¹å¼çš„æ¬¡æ•°
variance		æ–¹å·®
sanity check	åˆç†æ£€éªŒ
curves		æ›²çº¿
Error Analysis	è¯¯å·®åˆ†æ
skewed classes	åæ–œç±»
æŸ¥å‡†ç‡(Precision)=TP/(TP+FP)  	Precision    ç²¾ç¡®
æŸ¥å…¨ç‡(Recall)=TP/(TP+FN)
Support Vector Machinesï¼ˆvapinkå‘æ˜ï¼‰	æ”¯æŒå‘ é‡æœº 
Quadratic Programming	äºŒæ¬¡è§„åˆ’
regulation term 	æ­£åˆ™é¡¹
slack variable	æ¾å¼›å˜é‡
prime problem	åŸé—®é¢˜
data compression 	æ•°æ®å‹ç¼©
ä¸»æˆåˆ†åˆ†æ(PCA)æ˜¯æœ€å¸¸è§çš„é™ç»´ç®—æ³•ã€‚
Projected Error		æŠ•å°„è¯¯å·®
Anomaly detection		å¼‚å¸¸æ£€æµ‹
SGD	éšæœºæ¢¯åº¦ä¸‹é™æ³•
Rectified Linear Unit			ä¿®æ­£çº¿æ€§å•å…ƒ
Recurrent Neural Network		é€’å½’ç¥ç»ç½‘ç»œ
Convolutional Neural Network	å·ç§¯ç¥ç»ç½‘ç»œ
Neural Network Overviewï¼‰		ç¥ç»ç½‘ç»œæ¦‚è¿°
å¾ªç¯(loop)
optimer ä¼˜åŒ–
Dimensionality reduction   é™ç»´
estimate ä¼°è®¡

ç™½æ¿ä¹¦æ¨å¯¼ï¼š
*------------------------------------------------------------------------------------------------------*
æå¤§ä¼¼ç„¶ä¼°è®¡æ–¹æ³•ï¼ˆMaximum Likelihood Estimateï¼ŒMLEï¼‰
æ¦‚ç‡å¯†åº¦å‡½æ•°  probablity dense function
æ„ŸçŸ¥æœº	Perceptron 
